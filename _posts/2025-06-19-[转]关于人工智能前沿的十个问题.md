---
title: '关于人工智能前沿的十个问题'
date: 2025-06-19
permalink: /posts/2025/06/关于人工智能前沿的十个问题/
tags:
  - Future of AI
  - Foundational AI Questions
  - AI Trends 2025
---

# 关于人工智能前沿的十个问题

> 本文转自上海人工智能实验室（Shanghai AI Lab），系上海人工智能实验室主任、首席科学家，清华大学惠妍讲席教授周伯文于2025年6月13日在星河学术社区首届明珠湖会议所作的开场报告。

## 科学社区的力量：创新的摇篮

欢迎各位专家与青年朋友参加明珠湖会议。

我们今天正式启动了一个全新的科学社区——星河社区。首先我想分享几个故事，跟大家探讨一下，为什么需要科学社区的力量。

众所周知，现代科学起源于英国，英国现代科学的一个典型标志是英国皇家学会，它成立于1660年，是世界上历史最悠久、从未中断的科学学会。但其实它有着更久远的渊源——一群科学家在1618年发起了非正式运行的“隐形学院”（Invisible College）——这种紧密的交流塑造了近代科学精神。例如，英国皇家学会成员中，牛顿奠定了经典力学基础，霍金则在黑洞理论和宇宙学中揭示了时空的奥秘。

科学研究离不开思想碰撞。另一方面，现在追求创新链和产业链的融合，在产业链，也一样需要碰撞和交流。

1765年，工业革命的发源地英国伯明翰诞生了一个社区——这也印证了科学先行、技术跟随的理念。这一社区最早的发起人有瓦特等在工业革命史留下名字的人，他们以组织晚餐俱乐部的形式定期聚会。聚会时间往往选择在满月之夜，因为在没有路灯的情况下，月光可以帮他们照亮回家的路——这个团体因而取名为“月光社”（Lunar Society）。“月光”社孕育了许多著名人物，如“热力学之父”开尔文勋爵；也催生了许多突破性的发明发现，如博尔顿与瓦特公司（Boulton & Watt）对蒸汽机的改造推动了第一次工业革命。

时钟拨转到20世纪，在计算机领域，美国高级研究计划局（Advanced Research Project Agency）在1960年代资助了众多美国计算机科学领域的研究。其中一项划时代的工作是阿帕网（ARPANET）——全球互联网的鼻祖。

阿帕网还带来了一个“副产品”。

最初的“阿帕网”，由西海岸的4个节点构成，包括加州大学洛杉矶分校（UCLA）、斯坦福研究院（SRI）、加州大学圣巴巴拉分校（UCSB）和犹他大学（UTAH）。后来阿帕网陆续扩展到其他大学。

在计算机历史的重要著作《The Dream Machine》（梦想机器）中，记录了个人计算机和互联网诞生背后关键的一群人，其中的一个故事是：阿帕网各个节点所在的高校，每年会派出各自实验室最优秀的青年聚在一起，既参加封闭研讨，也并肩滑雪、交流谈心——就好像今天的明珠湖会议一样。这群人自称为“阿帕社区”（ARPA Community），从美国西海岸到东海岸，横跨美国大陆的这批青年学者在此过程中建立起了紧密的友谊和共同的目标。

这个社区最了不起的成果之一，就是成就了一批优秀的成员。尽管随着时间的流逝，阿帕网逐渐淡出了历史舞台，但“阿帕社区”的成员继续协作。其中有的人从学术界进入到产业界，参与创造出了个人计算机、GUI、面向对象编程、激光打印机、点对点网络、PostScript界面等划时代的成果。这个社区有7位成员先后获得了图灵奖。

## 对发现问题的投入，与解决问题同样重要

基于上述出发点，我认为我们首先要做的是提出问题、发现问题。

在科学研究领域，对发现问题的投入与解决问题同样重要——这一点在科学界早有共识，但没有得到足够重视。

“阿帕社区”成员之一，艾伦·凯（Alan Kay，面向对象编程与GUI先驱，2003图灵奖获得者）曾说：相比解决问题的过程，对发现问题的过程进行资助往往更重要，但这一过程往被忽视。“辛烷值”提出者、雷达系统设计者之一亨利·蒂泽德（Henry Tizard）认为，“科学的秘密在于提出正确的问题，而**对问题的选择是否得当**是科学天才的重要标志。”

另一个例子是计算机科学、数学家理查德·汉明（Richard Hamming）。由于他喜欢追着别人问“你们领域最关键的问题是什么”，因而在社交场合一度不太受欢迎。他这么问一方面是为了用“那你们为什么不研究这些问题呢？”来调侃对方，另一方面则是因为这个问题确实能有效引导人们聚焦于真正重要的问题。这两个问题被称为“**汉明问题**”（Hamming Questions）。

历史证明，能回答这两个问题的人都在各自领域大有成就，而那些不能回答的人则默默无闻。所以说，这就是提出好问题的力量。

今天，我们召开明珠湖会议，正是基于对社区力量、提出问题的重视。希望通过这个平台，聚集志同道合挑战科学边界的研究者，让大家充分思考、讨论，甚至激辩，从而发现问题，提出问题，并尝试找到答案。

在会议的组织上，我们也尝试了一系列创新。首先，通过引导报告提出问题；其次，通过“结对报告”（Pair Talk，让观点不同的人做同一个报告）凝练问题；最后，在平行论坛环节深化问题。明珠湖会议的目标聚焦于提出问题，让参与者抛开资金和资源限制，思考自己真正愿意研究的问题。

与其他学术会议不同的是，我们希望明珠湖会议能做到以终为始、战略引领。因此，我们讨论的问题都有明确的时间边界，聚焦18-36个月的技术窗口期——通过这种设定，让大家专注于真正重要的问题。

在问题导向的过程中，我们希望参与者专注于“干什么”，而无需受到学历、资历和组织架构等因素的限制。

我们还希望结合国家在人工智能创新领域的支持，帮助大家快速落地研究成果。明珠湖会议的预期产出是具有颠覆性的关键问题清单，并初步形成敏捷部署提案。在成果落地方面，我们有丰富的载体，如上海人工智能实验室的开放课题、“AI4S攀登者行动计划”等项目，以及上海市和国家相关重大研究项目等，可以从不同的层次、资金规模和边界条件出发，为提出的问题找到适配的规划路径。最终沉淀下来的关键问题还将面向社区开放，邀请更多有能力的同行者进行“答题”。

## **AI前沿十问：未来关键技术节点**

本次会议的主题是“人工智能的多维突破与协同创新”，关于人工智能未来3-5年发展趋势，我尝试总结为“三化”。

第一个是**智能技术体系化**。人工智能是一个非常典型的先发展应用，后补充理论的一个学科，发展到现在这个阶段，需要更体系化地去追究智能的本质，更好地去完善这个体系。

第二个是**智能形态多元化**。习近平总书记多次强调要“加强人工智能和产业发展融合”“突出应用导向”“加速各领域科技创新突破”。

所以人工智能一定要产生不同的形态，和实体经济、社会发展、人民生活紧密结合，随着人工智能技术的迭代，它一定会出现智能形态多元化。形态多元化的核心原因，一个是场景丰富度的要求，另一个是因为技术不完备，人工智能未来四五年中还会处于一个技术待完备的过程，这时候就需要妥协，在应用中考虑新的形态。所以这里就带来一个新问题，要思考人工智能产业的形态呈现出来的是过程还是终局，是手段还是目的？在这一点上，我们要充分听取来自学术界、产业界和投资界的声音。

第三个是**智能能力高阶化**。行业往前发展的核心动力是智能能力必须不断进行高阶化演进。今天的人工智能已经让大家惊叹，但我相信这仅仅是开始。高阶化离不开技术体系化，离不开要素的突破，离不开对形态的理解。否则，基于中阶过程去探讨人工智能的高阶化，就有可能走上错误的道路。

以上是我针对“人工智能未来发展趋势”的框架性思考，而针对人工智能未来关键技术节点的判断，我总结提出了十个问题，这些问题至今还没有确定的答案。今天借此机会与大家分享，希望可以和大家一起探讨。

### **1、总体智能** **vs** 单位智能：如何平衡智能发展的质量与效率？

我们从去年开始思考：当前评估模型时，往往关注总体智能——参数规模、训练数据量和排行榜排名。而忽略了另外一个也很重要的指标——**单位智能**（IQ per token）。这一指标涵盖数据成本、计算成本和存储成本，类似于经济学中的人均GDP概念。

在模型评估中，若能实现单位智能最大化，那么总体智能将会显著提升。DeepSeek模型的工程创新使模型更为简洁，这种简洁本身就是智能的高级表现。2025年1月，上海人工智能实验室正式提出数据思维密度（IQPT，Intelligence Quality per Token），定义为模型平均性能与训练数据量的比值，可以衡量大模型训练数据的“投入产出比”。今年3月，OpenAI研究负责人诺姆·布朗（Noam Brown）也分享了单位成本智能的相关观点。

### **2、Deep RL规模化发展的资源悖论：如何平衡“数据合成”和“算法训练”两大任务的算力分配？** 

深度强化学习（Deep RL）不仅是学习手段，同时也是一条能够产出高价值数据的高效路径。在运行过程中，它一方面会消耗一定的算力资源，另一方面却能生成具备高精度、高密度特性的复杂推理数据。值得关注的是，这些合成数据可以反哺预训练环节，从而显著提升模型性能。

因此，在理想状态下，我们可以追求**效率飞轮**：通过Deep RL消耗的算力与其产生的高质量数据所节省的训练成本达成平衡。当这个临界点到来，AI或将能以极低成本自我提升，实现“自己训练自己”。

### 3、软硬协同创新：软件向硬件适配，还是硬件向软件兼容？

软硬协同的路径国内外存在差异，国际厂商如英伟达选择 “软件兼容硬件”，通过深耕CUDA生态，使其软件能够高度适配自家硬件；而国内目前更多是“硬件兼容软件”，例如芯片厂商调整算子以适配软件需求。

然而，硬件研发的周期通常要比软件长得多，这就导致“硬件兼容软件”这条路径在逻辑上遭遇了挑战。学术界应探索更高效的软硬协同创新路径，既要实现软硬件在性能上的优化，也要紧密贴合产业实际需求，为产业发展提供更有力的支持，促进整个产业链的良性循环与升级。

### 4、算力受限的影响：针对应用、迭代和颠覆性的技术，算力应如何配置？

从算力运用的维度来看，可将其划分为三类：

一是应用算力（For Application），聚焦于已明确的场景应用，通过加大算力投入，全力推动科研成果实现产业落地，将理论转化为实际生产力，促进产业的发展与升级。

二是迭代算力（For Incremental），此类算力助力研究工作持续推进与模型迭代优化，例如依据 Scaling Law 投入算力开展模型训练等相关工作。

三是创新算力（For Disruptive），其核心作用在于对非主流想法进行验证，积极探索更多尚未被充分发掘的新技术，拓展多样化的新解决方案。

当前，应用算力和迭代算力相对充足，而创新算力严重不足，这对于颠覆性想法的产生与发展形成了潜在挑战。要想避免研究走向同质化困境，实现创新算力供给至关重要。这种供给应当鼓励差异化思考，并为非主流技术路线提供支持。

### 5、Agent与基础模型的关系：Agent是目的还是过程？如何构建真正自主进化的智能体？

早在2023年，我们便提出下一代大模型操作系统应该是融合语言能力的工具平台，其实与现在的Agent不谋而合。Agent和基座模型是什么样的关系？Agent是目的还是手段？这值得我们思考。

从Agent发展情况看，它是依赖于基础模型的，同时还需要通过与环境和用户的互动不断学习和自我改进。当前大多数自我改进系统都陷入了“僵化学习”的困境 。DeepMind科学家乔纳森·里奇恩斯（Jonathan Richens）今年6月发布论文，表明实现具有通用智能的智能体（AGI），必然学习到了环境的预测模型（世界模型）。无论是在动态环境中，还是在任务复杂度日益上升的背景下，世界模型都是不可或缺的基础。

人类智能的一个核心特征便是其永无止境的学习能力——不断吸收新知识、适应环境变化，并对过往经验进行深刻的总结、迁移与升华。智能体系统是否也有可能具备类似的、真正意义上的持续学习能力，甚至在此基础上实现某种形式的“自主进化”？

### 6、具身智能：超级大脑与本体的关系? 如何突破“莫拉维克悖论”？实现类人的具身进化和环境自适应？

在具身智能的研究范畴里，如何精准定义 “大脑” 与 “本体” 之间的关系，已成为核心且亟待攻克的关键问题。人类作为“智能体”，在本体能力维度，诸如力量、速度等方面，人类相较于众多动物存在明显劣势。然而，人类却凭借独特的工具创造能力、环境交互与学习的能力，成功突破了自身生理局限，达成诸多超越想象的成就。

因此，未来的具身智能研究应当深入探究大脑与本体间的最优关系，并据此制定资源投入的最佳策略。既避免“超级大脑-弱本体”的陷阱，也避免“高级本体-简单决策”的陷阱。从而推动具身智能技术取得实质性、突破性进展。

### 7、安全可信 vs 智能：如何从Make AI Safe 到 Make Safe AI？

人工智能正以前所未有的速度发展，当前面临的核心挑战是：如何从被动的“弥补AI安全漏洞”（Make AI Safe）转向主动的“构建本质安全的AI”（Make Safe AI）?

2024年，我们提出“人工智能45°平衡律”：安全不应是AI系统的后期附加功能，而必须作为核心设计原则贯穿始终。2025年，约书亚·本吉奥（Yoshua Bengio）倡导的“设计即安全”（Safety by Design）也反映出这一点。

近期，形式化AI取得较多进展，华裔数学家陶哲轩的“Lean+AI=数学证明智能化”概念，以及创业公司Ndea的程序合成（program synthesis）技术，都体现了通过数学严谨性确保系统行为可验证。形式化AI有巨大潜力，但同时也存在一定的问题：会否由于限制太强，使系统灵活度下降，从而出现为了完成任务而“绕过安全检查”，最终导致病变？自动形式化、形式化验证是确保AI 100% 安全的路径吗？还有哪些可行的技术方案，比如Causal AI（因果人工智能）、Explainable AI（可解释人工智能）等？真正的AI安全需要的不是完美的规范，而是具备自我修正能力的动态安全机制。

### 8、高分 vs 高能：从静态到动态? 训练、评测、解决问题一体化？面向AGI的评测应如何建设？

“AI上半场”聚焦于开发新的训练方法和模型架构，但模型任务与真实世界的“效用”存在脱节，暴露出当下评测体系“高分低能”的问题。因此“AI下半场”将聚焦于“现实世界的任务定义与评估体系重构”。

新评测体系要从能力导向（构建评测问题）到任务导向 （独立/辅助人类解决现实世界中的高价值问题）迁移，评测和解决问题可能会变成一体化，即在训练中评测、在评测中训练，在“干中学”在“学中干”。

2025年4月，我们发布了“测试时强化学习”（Test-Time Reinforcement Learning, TTRL）框架研究论文，探索在没有准确标签的情况下进行奖励估计，驱动模型朝着正确的方向学习。同期，Google DeepMind 强化学习团队副总裁David Silver与图灵奖得主、强化学习之父Richard Sutton共同发表文章《Welcome to the Era of Experience》，与TTRL框架理念相似。

### 9、下一代AI for Science：如何从“工具的革命”到“革命的工具”？

AI for Science要真正发挥革命性作用，必须理解科学研究的本质：研究者、研究工具、研究对象三者的交互关系。目前的AI for Science主要关注研究工具层面的单点效率提升（“工具的革命”），而我们需要追求的是能够带来科学范式转变的“革命性工具”，并实现科研各环节全链条水平提升。下一代For Science的AI，如何从“工具的革命”变成“革命的工具”应该是我们这一代人的使命。

如果要成为“革命的工具”，现在的语言模型是否够用？若没有多模态的智能涌现，或许很难实现革命性的AI for Science工具。当前的多模态模型仍然建立在预测下一个token的基础上，缺乏对图表、分子模型、公式和实验观察的深度理解能力。打造能够推动科学突破的AI系统，需要在多模态统一表征方面取得突破。

### 10、颠覆性架构是什么？针对Transformer的不足，什么架构能够带来根本性创新？

Transformer架构自2017年问世以来，引领了AI领域的一场革命。从GPT系列到Claude，从DALL-E到Gemini，几乎所有令人印象深刻的大型语言模型和多模态模型都建立在这一架构之上。然而，随着我们对AI能力的期望不断提高，Transformer的一些内在局限性逐渐显现，包括计算效率不高、上下文理解有限、推理能力存在瓶颈、难以模拟动态系统等。正如爱因斯坦所言：“我们不能用制造问题时的思维方式来解决问题”。突破这些局限，可能需要全新的架构思路。展望未来，除了Transformer自身架构的持续迭代，未来多元架构如何共存、互补和协作？针对决策智能、世界智能、生物智能等领域需要探索可能引领下一代的AI架构。

## **如何实现战略科学家“群体涌现”**

上面讨论了科学社区及提出好问题的重要性，如果我们把目光投向更聚焦的人群——战略科学家，就会发现，在许多关键的历史时期，都出现了战略科学家“群体涌现”的效应。

例如，1920年代，世界上涌现出了一批史称匈牙利“黄金一代”的战略科学家，包括计算机之父冯·诺依曼、氢弹之父爱德华·特勒，以及钱学森的导师——超音速飞行之父冯·卡门等。1970至80年代PC革命，美国涌现出比尔·盖茨、乔布斯等，他们均出生于1955年。如今人工智能领域也出现了顶尖科技人才集聚效应，OpenAI发布世界首个深度思考与推理大模型o1，其核心技术的七位负责人中，五位来自波兰。

但是，战略科学家人选难以在早期预判。二战后，美国基础研究奠基人范内瓦·布什（Vannevar Bush）曾在给美国总统杜鲁门的信中写道：“战略科学家的形成是一个长期且复杂的过程，涉及个人智力、意愿、身体健康、精力、目标导向等多个方面”。

历史证明，战略科学家往往在承担重大任务时，在有研判、有管理、有组织能力的群体中产生。承担重大科研攻关项目是成为战略科学家不可或缺的条件。以我国的“两弹一星”工程为例，大量科学家通过参与这一国家重大科技工程，不仅发挥出其卓越的科研能力，也展现了非凡的战略眼光和领导力。

我们一直把科学社区问题驱动作为培养战略科学家的输入点，并为战略科学家成长创造条件。当前通用人工智能处于爆发前夜，存在非常难得的窗口期，亟待通过重大组织模式创新，发现、选拔，并培育出一批战略科学家。

实验室广泛链接国内外优秀科研团队和人才，并探索通过构建科学社区，形成战略科技人才蓄水池，以问题为驱动，形成“**高强度要素投入+高集中任务攻关+高密度人才历练场**”三位一体的培育模式，让真正有潜力的青年科学家在潜心研究的过程中，持续提升前瞻性判断、跨学科理解能力、组织领导等核心能力，最终成长为战略科学家。