---
title: '一点关于正则化的笔记'
date: 2025-07-19
permalink: /posts/2025/07/一点关于正则化的笔记/
tags:
  - Machine Learning
  - Regularization
---



最近被同学问到了机器学习里正则化这一概念的一些问题，包括如何理解 L1 和 L2 正则化起到的效果。在讨论的过程中，我们从约束的角度尝试理解了为什么 L1 正则化可能使参数为 0，而 L2 正则化更倾向于缩小参数。

---
## 正则化的概念

首先回顾一下正则化的相关概念：

> 为了防止模型过拟合，机器学习中经常会在损失函数中加入正则项，称之为**正则化（Regularization）**。通过在损失函数上加上某些规则（限制），缩小解空间，从而减少求出过拟合解的可能性。

设目标函数为 $f(w)$，正则项为 $R(w)$，则带正则项的优化问题表示为：
$$
\min_{w \in \mathbb{R}^n} \; f(w) + \lambda R(w)
$$
其中：
- $w \in \mathbb{R}^n$ ：模型参数；
- $f(w)$：经验损失函数（如平方误差、交叉熵等）；
- $R(w)$：正则项（regularizer）；
- $\lambda > 0$：正则化系数，调控正则项与损失项之间的权衡。

> **L2 正则化**，又称为 **Ridge 正则化**，通过惩罚参数向量的 L2 范数平方，鼓励权重向量整体收缩（shrinkage），从而提升模型的稳定性与泛化能力。


L2 正则项定义为参数平方和：

$$
R_{L2}(w) = \|w\|_2^2 = \sum_{i=1}^{n} w_i^2
$$

对应的正则化优化问题为：

$$
\min_{w \in \mathbb{R}^n} \; f(w) + \lambda \|w\|_2^2
$$

L2 正则化具有一些基本特性：

- **可导性强**：L2 正则项为光滑函数（smooth function），一阶导数连续，因此适用于梯度下降类优化方法。

- **整体收缩效应（Weight Shrinkage）**：L2 正则化会对每个参数 $w_i$ 施加与其平方成正比的惩罚项。对于绝对值较大的权重，其平方更大，惩罚显著；而对于接近零的权重，其平方趋近于零，几乎不受到惩罚。具体而言：

  $$
  \text{若} \ |w_i| \gg 1 \Rightarrow w_i^2 \gg 1 \Rightarrow \text{惩罚项大} \\
  \text{若} \ |w_i| \ll 1 \Rightarrow w_i^2 \ll 1 \Rightarrow \text{惩罚项小}
  $$

  因此，L2 正则化不会诱导稀疏性（不会使 $w_i$ 精确为 0），但能有效抑制过大的权重。

- **数值稳定性与解的存在性（闭式解）**：在使用正规方程（Normal Equation）求解线性回归参数时，L2 正则化能确保矩阵求逆时始终存在逆，即使特征矩阵 $X$ 存在共线性问题。令目标函数为最小二乘损失：

  $$
  \min_{w} \; \|Xw - y\|_2^2 + \lambda \|w\|_2^2
  $$

  对应的解析解为：

  $$
  w^* = (X^\top X + \lambda I)^{-1} X^\top y
  $$

  由于 $\lambda > 0$，矩阵 $X^\top X + \lambda I$ 始终是正定的，从而保证其可逆性，即逆 $(X^\top X + \lambda I)^{-1}$ 一定存在。这一性质提升了数值计算的稳定性。

> **L1 正则化**，又称为 **Lasso 正则化**，通过最小化参数向量的 L1 范数（即绝对值之和）来鼓励稀疏性。

具体而言，L1 正则项定义为：
$$
R_{L1}(w) = \|w\|_1 = \sum_{i=1}^{n} |w_i|
$$

优化问题为：

$$
\min_{w \in \mathbb{R}^n} \; f(w) + \lambda \|w\|_1
$$


随着大规模特征数据的广泛应用，工业场景对模型的稀疏性和可解释性提出了更高要求。此时，L2 正则化已无法满足实际需求：虽然它可压缩参数幅度，使其趋近于零，但不会使权重真正等于零，因此无法直接“舍弃”冗余特征。

相比之下，L1 正则化具有明确的 **稀疏性诱导能力**。它在优化过程中倾向于使大量参数权重精确地收缩为零，进而实现显式的特征选择。优化完成后，所有满足 $w_i = 0$ 的特征可被忽略，从而减少模型存储与计算负担。


> **L0 正则化** 直接对参数向量中非零元素的个数进行惩罚，鼓励模型尽可能地使用更少的参数，从而达到稀疏性目的。

令 $w = (w_1, w_2, \dots, w_n)^\top \in \mathbb{R}^n$，L0 正则项定义为：

$$
R_{L0}(w) = \|w\|_0 = \sum_{i=1}^{n} \mathbf{1}_{w_i \ne 0}
$$

对应的优化问题为：

$$
\min_{w \in \mathbb{R}^n} \; f(w) + \lambda \|w\|_0
$$

从直观上看，利用非零参数的个数，可以很好的来选择特征，实现特征稀疏的效果，具体操作时选择参数非零的特征即可。但因 L0 正则化很难求解，是个 NP-hard 问题，因此一般采用 L1 正则化。L1 正则化是 L0 正则化的最优凸近似，比 L0 容易求解，并且也可以实现稀疏的效果。

---

## 正则化问题与约束问题等价性的数学推导

### 问题设定
设 $f: \mathbb{R}^n \to \mathbb{R}$ 为目标函数，$R: \mathbb{R}^n \to \mathbb{R}$ 为正则项或约束项。我们考虑以下两类优化问题：

**（1）正则化形式（惩罚形式）**：

$$(\mathbf{P1}) \quad \min_{w \in \mathbb{R}^n} \; f(w) + \lambda R(w), \quad \lambda > 0$$

**（2）约束形式**：

$$(\mathbf{P2}) \quad \min_{w \in \mathbb{R}^n} \; f(w) \quad \text{s.t.} \; R(w) \leq C, \quad C > 0$$

我们的目标是说明：在适当条件下，存在一一对应的参数 $\lambda \leftrightarrow C$，使得问题 $(\mathbf{P1})$ 与 $(\mathbf{P2})$ 在最优解上等价。


### 拉格朗日对偶性构建

考虑约束问题 $(\mathbf{P2})$：

$$
\min_{w \in \mathbb{R}^n} \; f(w) \quad \text{s.t.} \; R(w) \leq C
$$

构造其 **拉格朗日函数**：

$$
L(w, \lambda) = f(w) + \lambda (R(w) - C), \quad \lambda \geq 0
$$

定义对应的 **拉格朗日对偶函数** $g(\lambda)$ 为：

$$
g(\lambda) = \inf_{w \in \mathbb{R}^n} L(w, \lambda) = \inf_{w} \left[ f(w) + \lambda (R(w) - C) \right]
$$

则对应的对偶问题为：

$$(\mathbf{D}) \quad \max_{\lambda \geq 0} \; g(\lambda)$$

### 对偶函数提供原问题的下界

对于任意 $\lambda \geq 0$，有：

$$
g(\lambda) \leq f(w), \quad \forall w \; \text{s.t.} \; R(w) \leq C
$$

因此，$g(\lambda)$ 是原问题 $(\mathbf{P2})$ 最优值的下界：

$$
g(\lambda) \leq f^*, \quad \forall \lambda \geq 0
$$

其中 $f^*$ 表示原问题的最优值。

### 强对偶性与等价条件

若满足：

- $f(w)$ 为凸函数；
- $R(w)$ 为凸函数；
- 存在严格可行解 $\exists w_0, \; R(w_0) < C$（满足 Slater 条件）；

则根据凸优化中的 **强对偶性定理**，有：

$$
\max_{\lambda \geq 0} g(\lambda) = \min_{w, \; R(w) \leq C} f(w) = f^*
$$

并且，若 $w^*$ 为原问题最优解，$\lambda^*$ 为对偶问题最优解，则 $(w^*, \lambda^*)$ 满足 **KKT 条件**。

### KKT 最优性条件

设约束函数 $g(w) := R(w) - C$，则 KKT 条件包括：

- **原始可行性（Primal feasibility）**：

  $$
  R(w^*) \leq C
  $$

- **对偶可行性（Dual feasibility）**：

  $$
  \lambda^* \geq 0
  $$

- **互补松弛性（Complementary slackness）**：

  $$
  \lambda^* (R(w^*) - C) = 0
  $$

- **最优性条件（Stationarity）**：

  $$
  \nabla f(w^*) + \lambda^* \nabla R(w^*) = 0
  $$

### 与正则项问题的对应关系

正则化问题 $(\mathbf{P1})$：

$$
\min_{w} \; f(w) + \lambda R(w)
$$

可以视为约束问题 $(\mathbf{P2})$ 的 **拉格朗日松弛形式**，其中 $\lambda$ 为拉格朗日乘子，$C$ 为约束上限。

若 $(w^*, \lambda^*)$ 满足 KKT 条件，则 $w^*$ 同时是 $(\mathbf{P1})$ 与 $(\mathbf{P2})$ 的最优解，且最优值相等。

因此，在满足强对偶条件的前提下，可建立如下参数映射关系：

- 对于每个 $\lambda > 0$，存在唯一的 $C = R(w^*(\lambda))$ 使得 $(\mathbf{P1})$ 与 $(\mathbf{P2})$ 等价；
- 反之，对于每个 $C > 0$，存在对应的 $\lambda(C)$ 使等价成立。

### 结论

**定理（正则化-约束等价性）**：

设 $f(w)$ 和 $R(w)$ 为凸函数，且存在 $w$ 满足 $R(w) < C$。则以下两个优化问题：

- 正则化形式：

  $$
  \min_{w} \; f(w) + \lambda R(w)
  $$

- 约束形式：

  $$
  \min_{w} \; f(w) \quad \text{s.t.} \; R(w) \leq C
  $$

在某些参数对 $(\lambda, C)$ 下具有**相同的最优解**，并且满足强对偶性，最优值相等。

---

## 从约束优化角度理解 L1 与 L2 正则化的直观意义

根据前述推导，正则化问题：

$$
\min_{w \in \mathbb{R}^n} \; f(w) + \lambda R(w)
$$

在满足一定条件（如 $f(w)$ 与 $R(w)$ 为凸函数，且存在严格可行解）下，与约束问题：

$$
\min_{w \in \mathbb{R}^n} \; f(w) \quad \text{s.t.} \; R(w) \leq C
$$

是**等价的**，其中 $\lambda > 0$ 是拉格朗日乘子，$C > 0$ 为约束上限。这一结论为我们提供了对常用正则项的更直观几何解释：


### L2 正则化约束：控制权重的欧氏长度

L2 正则化对应的正则项为：

$$
R_{L2}(w) = \|w\|_2^2 = \sum_{i=1}^{n} w_i^2
$$

其等价的约束形式为：

$$
\min_{w} \; f(w) \quad \text{s.t.} \; \|w\|_2^2 \leq C
$$

该约束表示所有参数向量 $w$ 必须落在一个以原点为中心的 L2 球（Euclidean ball）中，其几何形状是光滑的球面：

- 惩罚的是参数的整体**能量大小（length squared）**；
- 没有偏向任何坐标轴方向；
- 解通常为非稀疏的（所有参数趋于非零但较小）；
- 具有良好的数值稳定性与解析可解性。

### L1 正则化约束：控制权重的绝对值和

L1 正则化对应的正则项为：

$$
R_{L1}(w) = \|w\|_1 = \sum_{i=1}^{n} |w_i|
$$

其等价的约束形式为：

$$
\min_{w} \; f(w) \quad \text{s.t.} \; \|w\|_1 \leq C
$$

该约束限制参数向量必须位于一个以原点为中心的 L1 范数球（Manhattan ball）中。在二维情况下，该集合为菱形（diamond），在高维空间中呈现多面体状：

- 由于角点（vertices）落在坐标轴上，最优解倾向于出现在这些角点处；
- 导致大量参数为 $0$，实现稀疏性诱导；
- 适合特征选择与模型压缩等任务；
- 优化问题为凸但不可微（在 $w_i = 0$ 处）。

### 几何直观：等高线与约束边界的切点

考虑最小化损失函数 $f(w)$ 的等高线与正则项约束集合的几何交互：

- 在 L2 正则化下，等高线最早触碰到的是圆形边界的某点，通常落在内部平滑区域，导致参数非零但较小；
- 在 L1 正则化下，等高线更易在边角点处达到最小值，从而使某些维度精确为零。

### 小结

| 项目 | L1 正则化 | L2 正则化 |
|------|-----------|-----------|
| 范数定义 | $\|w\|_1 = \sum \|w_i\|$ | $\|w\|_2^2 = \sum w_i^2$ |
| 对应约束 | $\|w\|_1 \leq C$ | $\|w\|_2^2 \leq C$ |
| 几何形状 | L1 球（菱形/多面体） | L2 球（圆形/椭球） |
| 解的结构 | 稀疏，偏好角点（$w_i = 0$） | 平滑收缩，解非稀疏 |
| 应用场景 | 特征选择、模型压缩 | 防止过拟合、提升稳定性 |

因此，从约束角度理解 L1 与 L2 正则化，不仅揭示了其在几何与优化性质上的根本差异，也为正则项选择提供了理论依据和实践指导。